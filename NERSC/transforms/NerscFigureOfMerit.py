#!/usr/bin/env python
"""
Calculates price / preformance and figure of merit and
saves it into the output file acording to design document.

"""
from __future__ import division
import numpy as np
import pprint
import sys

from decisionengine.framework.modules import Transform

CONSUMES = ['Nersc_Instance_Performance',]

PRODUCES = ['Nersc_Price_Performance', 'Nersc_Figure_Of_Merit']


class NerscFigureOfMerit(Transform.Transform):
    def __init__(self, config):
        super(NerscFigureOfMerit, self).__init__(config)
        self.config = config

    def transform(self, data_block):
        """
         cat instance_performance_nersc.csv

         InstanceType,AvailabilityZone,OnDemandPrice,PerfTtbarTotal
         haswell,cori,0.576,0.96
         haswell_shared,cori,0.081,0.137
         knl,cori,0.612,0.255
         haswell,edison,0.432,0.658

         first column is HW type, second the machine, third the \"price\" of what we think
         1 hr of that resource is worth,

         and 4th the cms ttbar as measured by benchmarks you could rename it if you want but at the
         moment these first 4 columns correspond to the same names that the AWS price performance file has got

         the last number is the number of cms ttbar events that can be generated by that hardware config

         so therefore price/performance is the ratio of the 3rd and 4th column

         The harder question is how to take that into a figure of merit

         In AWS the figure of merit is just the price/performance rated by relative
         percentage of occupancy i.e. if we desire to have 50 jobs running at NERSC and we only have
         1 running right now, then we would weight the price performance by a factor of (1/50).
         remember in figures of merit, lower is better

          0.96 ttbar per second on the first line (cori haswell) means that all 64 cores
          of that machine working together produce 0.96 ttbar/s

          0.137 per second on the haswell shared line means that 8 cores produce 0.137 ttbar/s.
          and so forth.

          so for starters I would use an approach very similar to what is in the AWs figure of merit code.

          The difference is that this is much simpler since the prices never move
          for current occupancy you could use the NERSC source to get it directly (my preference)
          or get it from the factory entry. for the total limit of how many jobs that could also
          be gotten directly from the factory entry  (there's already a source to do that).

          I think the nersc_allocation source doesn't enter into the priceperf or figure of merit at all..
          however it will enter at the final request resources section that Parag is writing.

          The number of cores again is available from querying the factory with existing sources.
          Parag can get you the info needed on the right parameters there


          and I can answer quick things.. other than that then we should probably meet tomorrow
          sometime once you've had time to go over and digest this. but to summarize, I think the price perf/ figure 
          of merit is easy.
          the part that parag has to do--how many to request and when, is much more tricky in the NERSC situation
          because you can have a long delay between the time you request them and the time you get them.

        """

        performance = data_block['Nersc_Instance_Performance']
        performance['PricePerformance'] = np.where(performance['PerfTtbarTotal']>0, 
                                                   performance['OnDemandPrice'] / performance['PerfTtbarTotal'], 
                                                   sys.float_info.max)

        return {PRODUCES[0]: performance.drop(['OnDemandPrice','PerfTtbarTotal'], axis=1),
                PRODUCES[1]: {}}

    def consumes(self):
        return CONSUMES

    def produces(self):
        return PRODUCES

def module_config_template():
    """
    print a template for this module configuration data
    """

    d = {"NerscFigureOfMerit": {
           "module":  "modules.AWS.transforms.NerscFigureOfMerit",
           "name":  "NerscFigureOfMerit",
           },
        }
    print "Entry in channel cofiguration"
    pprint.pprint(d)
    print "where"
    print "\t name - name of the class to be instantiated by task manager"

def module_config_info():
    """
    print this module configuration information
    """

    print "consumes", CONSUMES
    print "produces", PRODUCES
    module_config_template()



def main():
    """
    Call this a a test unit or use as CLI of this module
    """
    import argparse
    parser = argparse.ArgumentParser()

    parser.add_argument('--configtemplate',
                        action='store_true',
                        help='prints the expected module configuration')

    parser.add_argument('--configinfo',
                        action='store_true',
                        help='prints config template along with produces and consumes info')

    args = parser.parse_args()

    if args.configtemplate:
        module_config_template()
    elif args.configinfo:
        module_config_info()

if __name__ == '__main__':
    main()
